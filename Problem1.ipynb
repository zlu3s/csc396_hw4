{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21cff5ee",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\"><b>Problem One: Average Contextualized Embeddings</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a20ec8",
   "metadata": {},
   "source": [
    "Load previous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65e94c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Vectors] Starting fresh\n",
      "[GloVe] Starting fresh\n",
      "[Gensim] Starting fresh\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# ---- 1. Vector totals checkpoint ----\n",
    "vector_checkpoint_path = \"vector_checkpoint.pkl\"\n",
    "if os.path.exists(vector_checkpoint_path):\n",
    "    with open(vector_checkpoint_path, \"rb\") as f:\n",
    "        saved = pickle.load(f)\n",
    "    vector_totals = saved[\"vector_totals\"]\n",
    "    token_count = saved[\"token_count\"]\n",
    "    start_i_vectors = saved[\"start_i\"]\n",
    "    print(f\"[Vectors] Loaded checkpoint at i = {start_i_vectors}\")\n",
    "else:\n",
    "    vector_totals = {}\n",
    "    token_count = {}\n",
    "    start_i_vectors = 0\n",
    "    print(\"[Vectors] Starting fresh\")\n",
    "\n",
    "# ---- 2. GloVe checkpoint ----\n",
    "glove_checkpoint_path = \"glove_checkpoint.pkl\"\n",
    "if os.path.exists(glove_checkpoint_path):\n",
    "    with open(glove_checkpoint_path, \"rb\") as f:\n",
    "        saved = pickle.load(f)\n",
    "    start_i_glove = saved[\"glove_words_done\"]\n",
    "    word_embeddings = saved[\"word_embeddings\"]\n",
    "    print(f\"[GloVe] Loaded checkpoint at batch {start_i_glove}\")\n",
    "else:\n",
    "    start_i_glove = 0\n",
    "    word_embeddings = {}\n",
    "    print(\"[GloVe] Starting fresh\")\n",
    "\n",
    "# ---- 3. KeyedVectors checkpoint ----\n",
    "gensim_checkpoint_path = \"gensim_checkpoint.kv\"\n",
    "if os.path.exists(gensim_checkpoint_path):\n",
    "    wv = KeyedVectors.load(gensim_checkpoint_path)\n",
    "    start_idx = len(wv)\n",
    "    print(\"[Gensim] Loaded KeyedVectors checkpoint\")\n",
    "else:\n",
    "    wv = None  # will initialize later\n",
    "    start_idx = 0\n",
    "    print(\"[Gensim] Starting fresh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fea900",
   "metadata": {},
   "source": [
    "Initialize System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "015dff3c-7ca9-43be-b03c-97439bcc7e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65180fc3",
   "metadata": {},
   "source": [
    "Now read in the assignment file and generate conextualized vectors for the tokens present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fbc4f-4b3a-4db2-b1f0-604b8793d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file\n",
    "file = \"assignment4-dataset.txt\"\n",
    "small = \"small.txt\"\n",
    "large = \"large.txt\"\n",
    "million = \"million.txt\"\n",
    "\n",
    "with open(large, 'r') as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b41a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save vector totals checkpoint\n",
    "import pickle\n",
    "\n",
    "vector_checkpoint_path = \"vector_checkpoint.pkl\"\n",
    "\n",
    "def save_vectors(i):\n",
    "    with open(vector_checkpoint_path + \".tmp\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"vector_totals\": vector_totals,\n",
    "            \"token_count\": token_count,\n",
    "            \"start_i\": i\n",
    "        }, f)\n",
    "    os.replace(vector_checkpoint_path + \".tmp\", vector_checkpoint_path)\n",
    "    print(f\"[Vectors] Checkpoint saved at i = {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process model output and accumulate vectors\n",
    "def get_vector(output, input_ids, attention_mask):\n",
    "    embeddings = output.last_hidden_state\n",
    "    for i in range(embeddings.size(0)):\n",
    "        token_ids = input_ids[i].cpu()\n",
    "        mask = attention_mask[i]\n",
    "        for j, id in enumerate(token_ids):\n",
    "            if mask[j] == 1:\n",
    "                vector = embeddings[i,j,:].cpu()\n",
    "                id_int = id.item()\n",
    "                if id not in vector_totals:\n",
    "                    vector_totals[id_int] = vector.cpu()\n",
    "                    token_count[id_int] = 1\n",
    "                else:\n",
    "                    vector_totals[id_int] += vector.cpu()\n",
    "                    token_count[id_int] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8733f7",
   "metadata": {},
   "source": [
    "Used the Facebook/Roberta-Base model to tokenize and convert to token ID's, and then to create contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8700aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Transformer name used\n",
    "name = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(name)\n",
    "model = RobertaModel.from_pretrained(name)\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 100\n",
    "save_every = 50\n",
    "for b, i in enumerate(range(start_i_vectors, len(lines), batch_size)):\n",
    "    tqdm.write(f'Processing lines {i} to {min(i+batch_size, len(lines))}...')\n",
    "    batch_words = lines[i:i+batch_size]\n",
    "    encoded = tokenizer(batch_words, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    # Create contextual embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        get_vector(output, input_ids, attention_mask)\n",
    "    \n",
    "    del batch_words, encoded, input_ids, attention_mask, output\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # save every N batches\n",
    "    if (i - start_i_vectors) % (save_every * batch_size) == 0 and i > start_i_vectors:\n",
    "        save_vectors(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd24ba",
   "metadata": {},
   "source": [
    "Create the average vectors for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2913a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_averages = {}\n",
    "for token in vector_totals:\n",
    "    vector_averages[token] = vector_totals[token] / token_count[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367cf29",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\"><b>Problem Two: most_similar() function</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fdc98",
   "metadata": {},
   "source": [
    "These are the ID's which should not be included in the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "751eada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_id: 0, end_id: 2, pad_id: 1\n"
     ]
    }
   ],
   "source": [
    "start_id = tokenizer.convert_tokens_to_ids('<s>')\n",
    "end_id = tokenizer.convert_tokens_to_ids('</s>')\n",
    "pad_id = tokenizer.pad_token_id\n",
    "print(f'start_id: {start_id}, end_id: {end_id}, pad_id: {pad_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042a9af",
   "metadata": {},
   "source": [
    "Using the glove file, find the token sequences associated with different words and gather the embeddings that pair with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "266380c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save GloVe checkpoint\n",
    "glove_checkpoint_path = \"glove_checkpoint.pkl\"\n",
    "\n",
    "def save_glove(i):\n",
    "    with open(glove_checkpoint_path + \".tmp\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"glove_words_done\": i,  # you can also save partial embeddings if needed\n",
    "            \"word_embeddings\": word_embeddings\n",
    "        }, f)\n",
    "    os.replace(glove_checkpoint_path + \".tmp\", glove_checkpoint_path)\n",
    "    print(f\"[GloVe] Checkpoint saved at batch {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "001e5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get word embeddings\n",
    "def get_word_embeddings(batch, input_ids):\n",
    "    for i, word in enumerate(batch):\n",
    "        ids = input_ids[i]\n",
    "        word_vector = []\n",
    "        for j in range(len(ids)):\n",
    "            token_id = input_ids[i][j].item()\n",
    "            if token_id == start_id or token_id == end_id or token_id == pad_id:\n",
    "                continue\n",
    "            if token_id in vector_averages:\n",
    "                word_vector.append(vector_averages[token_id])\n",
    "        if len(word_vector) == 0:\n",
    "            continue\n",
    "        word_vector = torch.stack(word_vector).mean(dim=0)\n",
    "        word_embeddings[word] = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GloVe vocabulary file\n",
    "glove_file = \"glove.6B.300d-vocabulary.txt\"\n",
    "with open(glove_file, 'r') as f:\n",
    "    glove_words = f.read().splitlines()\n",
    "\n",
    "# Process GloVe words in batches\n",
    "save_every = 500\n",
    "\n",
    "for b, i in enumerate(range(start_i_glove, len(glove_words), batch_size)):\n",
    "    tqdm.write(f'Processing lines {i} to {min(i+batch_size, len(glove_words))}...')\n",
    "    glove_batch = glove_words[i:i+batch_size]\n",
    "    glove_tokens = tokenizer(glove_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    glove_input_ids = glove_tokens.input_ids.to(device)\n",
    "    glove_attention_mask = glove_tokens.attention_mask.to(device)\n",
    "\n",
    "    get_word_embeddings(glove_batch, glove_input_ids)\n",
    "        \n",
    "    del glove_batch, glove_tokens, glove_input_ids, glove_attention_mask\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "     # save every N batches\n",
    "    if b % save_every == 0 and b > 0:\n",
    "        save_glove(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee0172",
   "metadata": {},
   "source": [
    "Make the words and their corresponding vectors into KeyedVectors so that we can use the most_similar() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0eef3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save KeyedVectors\n",
    "gensim_checkpoint_path = \"gensim_checkpoint.kv\"\n",
    "\n",
    "def save_wv():\n",
    "    wv.save(gensim_checkpoint_path)\n",
    "    print(\"[Gensim] KeyedVectors saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert word embeddings to KeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "hidden_dim = next(iter(word_embeddings.values())).shape[0]\n",
    "if wv is None:\n",
    "    wv = KeyedVectors(vector_size=hidden_dim)\n",
    "\n",
    "save_every = 10000\n",
    "words = list(word_embeddings.keys())\n",
    "vectors = [vec.numpy() for vec in word_embeddings.values()]\n",
    "\n",
    "\n",
    "for i in range(start_idx, len(words), batch_size):\n",
    "    tqdm.write(f'Processing words {i} to {min(i+batch_size, len(words))}...')\n",
    "    batch_words = words[i:i+batch_size]\n",
    "    batch_vectors = vectors[i:i+batch_size]\n",
    "\n",
    "    wv.add_vectors(batch_words, batch_vectors)\n",
    "\n",
    "    # save checkpoint every N batches\n",
    "    if (i // batch_size) % (save_every // batch_size) == 0:\n",
    "        save_wv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51dcee",
   "metadata": {},
   "source": [
    "Now do the most_similar() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "306eb783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cavalcanti', 0.9735779166221619),\n",
       " ('cavalcante', 0.9732860326766968),\n",
       " ('casket', 0.9722654819488525),\n",
       " ('calker', 0.9716652631759644),\n",
       " ('dotc', 0.971451997756958),\n",
       " ('cringe', 0.9713144898414612),\n",
       " ('criers', 0.9711087942123413),\n",
       " ('couderc', 0.9703741073608398),\n",
       " ('cossus', 0.970361053943634),\n",
       " ('cruce', 0.9703434109687805)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('cactus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7aec82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fruitcake', 0.9662887454032898),\n",
       " ('cakey', 0.9655447006225586),\n",
       " ('cakebread', 0.9634582996368408),\n",
       " ('cakewalk', 0.960048496723175),\n",
       " ('mooncake', 0.958672285079956),\n",
       " ('shortcake', 0.9537740349769592),\n",
       " ('cakelike', 0.9502132534980774),\n",
       " ('beefcake', 0.9404978156089783),\n",
       " ('poundcake', 0.9397675395011902),\n",
       " ('pattycake', 0.9386507272720337)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('cake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fadd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ryang', 0.9999999403953552),\n",
       " ('ryanggang', 0.9819610714912415),\n",
       " ('ryong', 0.9736228585243225),\n",
       " ('usry', 0.973404049873352),\n",
       " ('ryner', 0.9702824354171753),\n",
       " ('pry', 0.970122218132019),\n",
       " ('mlanghenry', 0.9697545170783997),\n",
       " ('terry', 0.9693702459335327),\n",
       " ('morry', 0.968619704246521),\n",
       " ('ryler', 0.9682397842407227)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38168ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clearly', 0.9788289070129395),\n",
       " ('quietly', 0.9755452275276184),\n",
       " ('dryly', 0.9753377437591553),\n",
       " ('fixedly', 0.9751794338226318),\n",
       " ('securely', 0.9747836589813232),\n",
       " ('smartly', 0.9746143221855164),\n",
       " ('hotly', 0.9745563864707947),\n",
       " ('cleanly', 0.9741897583007812),\n",
       " ('complexly', 0.9726245999336243),\n",
       " ('correctly', 0.9718415141105652)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('quickly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd1d80d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('betweenness', 0.9571166038513184),\n",
       " ('inbetween', 0.9554120302200317),\n",
       " ('inbetweeners', 0.9402250647544861),\n",
       " ('in-between', 0.9328943490982056),\n",
       " ('go-between', 0.932777464389801),\n",
       " ('bounderby', 0.9227321743965149),\n",
       " ('bytitle', 0.9213169813156128),\n",
       " ('byerley', 0.9161116480827332),\n",
       " ('byproducts', 0.9160301089286804),\n",
       " ('bynes', 0.9155882000923157)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('between')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b127fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('theile', 0.9662163257598877),\n",
       " ('theo', 0.9658365845680237),\n",
       " ('thea', 0.9654410481452942),\n",
       " ('thep', 0.9651058912277222),\n",
       " ('edythe', 0.9639862775802612),\n",
       " ('therence', 0.9637654423713684),\n",
       " ('lythe', 0.9636275768280029),\n",
       " ('theus', 0.9635955691337585),\n",
       " ('thean', 0.9631367325782776),\n",
       " ('theodo', 0.9628977179527283)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f74c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
